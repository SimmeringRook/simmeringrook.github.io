---
title: 1A
subtitle: MTH 420, S2022
author: Thomas Knudson
date: Monday, March 28, 2022
papersize: a4
geometry: margin=2cm
header-includes: |
    \usepackage{pgfplots}
    \usepackage{hyperref}
    \usepackage{tikz,tikz-3dplot} 
    \usepackage{tkz-euclide}
    \usepackage{fancyhdr}
    \usepackage{float}
    \usepackage{subcaption}
    \pagestyle{fancy}
    \fancyhead[RO,RE]{MTH 420, S2022}
    \fancyhead[CO,CE]{1A}
    \fancyhead[LO,LE]{Knudson}
---

## (a) Read the first half of Section 1.3 in Strang (pp. 15-21 top of page). Reread as needed for complete understanding.

## (b) Questions. Write clear responses to the following questions about the reading:

### (1) What is symmetry and how might it be important?

Geometric symmetry is very useful in simplifying physical equations by reducing a function of $n$ independent variables to a function of $k$ independent variables. For example, the electric field of a charge distribution exhibiting spherical symmetry, i.e. a point charge, or a *very far away* charge distribution, can be expressed as a vector field only depending on $r$: $\vec{E}(r, \phi, \theta) \rightarrow \vec{E}(r)$.

I see two important concepts of symmetric matrices:

1. if a matrix is symmetric, its commutative with respect to multiplication  
2. if a matrix is symmetric, we can change its basis representation without affecting its 'core properties'

For the first concept, this property becomes extremely useful for the matrix representations of operators by allowing simplifications through algebraic manipulations. This allows implies that we can find a common basis between two operators, assuming the commutator evaluates to $0$:

\begin{equation}
[ A, B ] = AB - BA \stackrel{?}{=} 0
\end{equation}

Discovering that two operators commute in quantum mechanics is very useful and tends to drastically simplify any calculations using the common set of basis eigenstates of $A$ and $B$. This is closely tied to the second concept, in which we can find matrices $L$ and $L^T$ such that the determinant of $A$ is equal to the determinate of $D$. In matrix form, this is how we can change from one orthonormal coordinate basis representation for $D$ into another.

For example, let $D$ be a diagonal matrix and $L_{q_1, q_2, q_3}$ represent the basis vectors of a generalized orthonormal coordinate system, $L_{q_1, q_2, q_3}{L_{q_1, q_2, q_3}}^T=I$. Then $A_{x,y,z}$ is the cartesian representation of $D$ by $L_{x,y,z} D {L_{x,y,z}}^T$ and is similar to the spherical representation $A_{r,\phi,\theta}$ through 

\begin{equation}
A_{r,\phi,\theta}=L_{r,\phi,\theta} A_{x,y,z} {L_{r,\phi,\theta}}^T= L_{r,\phi,\theta}L_{x,y,z} D {L_{x,y,z}}^T{L_{r,\phi,\theta}}^T.
\end{equation}

### (2) What is positive definiteness and how might it be important?

Positive definiteness is property that the determinant of $D$ is greater than $0$. Geometrically, this corresponds to a transformation that preserves orientation. For example, the transformation representing rotations in $\mathbb{R}^2$, 

\begin{equation}
A = \begin{pmatrix} \cos{\phi} & -\sin{\phi} \\ \sin{\phi} & \cos{\phi} \end{pmatrix},
\end{equation}

is positive definite and preserves the orientation. In contrast,

\begin{equation}
A^\prime = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix},
\end{equation}

is not positive definite (determinate $<0$) and reverses the orientation.

### (3) What do positive definite matrices have to do with optimization?

For the classification of optimization problems, if we can represent the given function as the the product of matrices,

\begin{equation}
f = x^T A x,
\end{equation}

then we are guaranteed a minimum value for $f>0$ (for $x>0$).

### (4) Give an additional question related to this reading (possibly about something well explained, or interesting, or confusing) and answer it if you can!

> How is Cholesky's method an improvement over Lagrange's?

It's not obvious to me as to why we might opt to use Cholesky's method for finding the minimum for an optimization problem. I understand the power (assuming my Part C algorithm is correct) of expression the function as the product of matrices, but I don't see how Cholesky's approach either simplifies or hastens this process.

## (c) Reflections. Write two or three sentences reflecting on the process of your work; this should only take a few minutes.  How did this first preparation assignment go? Was it pure review, or did you need to work hard to master these ideas?

I think I might need to work harder to master these ideas. I have a functional definition for each property, but I am unsure if I am missing a deeper meaning. For example, question 3 seems very straight forward to me:

- express the function to be optimized as the product of matrices
- determine if the diagonal matrix is positive definite for $x>0$
 - if yes: we have a minimum, find the coordinates using the first derivative test to establish critical points. No further steps required - we already have the equivalent to the second derivative test.
 - if no: there is no minimum (no solution); assuming we require $x>0$

## (d) Time. How much time did you spent on this assignment?

About 2 hours. I had to re-read the text a few times to find meaningful ways to express answers to the questions and to decouple the concepts from each other.