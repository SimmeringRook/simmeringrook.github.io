---
title: "Cartographer Progess Update"
subtitle: "11/2 - 11/22"
author: Thomas Knudson
papersize: a4
geometry: margin=2cm
output:
  pdf_document:
    toc: true
    toc_depth: 3
header-includes: |
    \usepackage{fancyhdr}
    \pagestyle{fancy}
    \fancyhead[RO,RE]{Knudson, For 11/22}
---

## Refactoring

### Making Dimensions Meaningful

The main achievement of the codebase for Novemeber 12 was the implementation of the dimensionless quantities for the arrays. Spurred by comments from Dr. David Roundy during PH 36X and most recently by Dr. Oksana Ostroverkhova during PH 651 while solving the Harmonic Oscillator in the position representation: *make everything dimensionless, especially when doing computation Physics*.

``` python
__r_domain = np.arange( 
        start=int(__start_r / __r_step_resolution), 
        stop=int(__stop_r / __r_step_resolution), 
        step=__r_iteration_direction
    )
```

From a usability standpoint, this was very benifical, as each corresponding coordinate array would scale at runtime according to any changed paramter. For example, if the previous run considered the interval of $(2M,10M)$ with a $dr_{bookkeeper}=1\ m$, increasing the resolution by changing $dr_{bk}=0.1$ automatically increased the (integer) number of steps from $2M$ to $10M$. The other main benefit of being very strict about bookkeeping dimensions of quantities allowed for the use of dimensional analysis to verify proper representations of calculations and to check when something needed to be scaled. Comparing the relation of $dr_{shell}$ to $dr_{bk}$ is an excellent example:

$$dr_{shell} = \frac{dr_{bk}}{\sqrt{1-\frac{2M}{r}}}$$

```python
def bookkeeper_meter_stick_as_measured_from_shell(proper_distance):
  '''
  Bookkeepr: This is a meter stick
  Shell: Uh, you should get a refund, because that's 5 times longer than its supposed to be!
  '''
  for r in __r_domain :
    proper_distance[ (r - __r_domain[0]) * __r_iteration_direction ] = .. 
      __r_step_resolution / np.sqrt(1 - (2*M)/(r*__r_step_resolution))
```

Recalling from above, `__r_domain` is a dimensionless interval of integer r-coordinates in the specified interval. `__r_step_resolution` serves as the bookkeeper's meter stick, $dr_{bk}$. Looking at the dimensions for the curvature factor, $\sqrt{1-2M/r}$, we see that in the program `r` is a dimensionless quantity, but in the mathematical formula, the entire expression is supposed to be dimensionless. This hints that `r` needs to be multiplied by something with dimensions of length to cancel out the dimensions from $2M$, but what should quantity should be used?

In this simple case, we add back the dimensions the same way we removed them: scaling by $dr_{bk}$; otherwise we would be obtaining the scale factor for some $r$-coordinate that was off by a factor of $1/dr_{bk}$. This can also be very quickly seen when calculating the corresponding lightclock tick rate with $$dt_{shell} = \sqrt{1-\frac{2M}{r}} dt_{bk}$$

```python
def bookkeeper_lightclock_tick_as_measured_from_shell(proper_time):
  for r in __r_domain :
    proper_time[ (r - __r_domain[0]) * __r_iteration_direction ] =  ..
      np.sqrt(1 - (2*M)/(r*__r_step_resolution)) * __time_step_resolution
```

Knowing that time has dimensions of length in GR, due to scaling by $c$, we could naively ask about using `__r_step_resolution` or `__time_step_resolution`. At the surface, this feels like a straightforward answer, but there's an added layer of complexity.

We're talking about time and the resolution should depend on the precision as specified by $dt_{bk}$. However, at the same time, we're talking about what the difference in clock tick rates are at each distance along some `r` interval. The context is the deciding factor: we want to measure the disagreement between the physical observation and the geometric expectation along some distance, therefore we iterate over `__r_domain` and scale `r` by $dr_{bk}$.

\pagebreak

### Breaking the Monolith

With the plots of physical vs geometric measurements working as expected, it was time to refactor the code. Most of what existed in `dimensionless_plot.py` was already fairly descriptive and narrative, there wasn't much to add in terms of comments or renaming variables. What was apparent, however, was the growing friction in changing the runtime parameters to see how the plots changed for different mass black holes or for different intervals.

One of the original design concepts behind Cartographer was to allow a configuration file to be supplied to specify these parameters. Then the comparision between different situations would be a simple matter of swapping out configuration files and allowing for a method to easily save the state that generated a series of plots.

This is then the perfect time to start dividing up sections of the code into logical files:

```
/Cartographer/
              spacetime/
                        schwarzschild.py
              Cartographer.py
              configuration_reader.py
              coordinate_array.py
              runtime_configurations.yaml
```

Cartographer, as its name suggests, should really just focus on generating the plots, and while being the namesake of the project, should also be the host of the service.

```
Cartographer.py
    | -- make_plot(...)
    | -- main(...)
```

In order to begin to calculate or plot anything, we first need to read in the configuration file:

``` python
import configuration_reader as cf_r

def main():
  coordinate_domains = cf_r.get_configuration_settings()
  if len(coordinate_domains) == 0:
    print('''Error in loading runtime_configurations.yaml.
     Check to make sure the file is located in the 
     same directory and has content.''')
    return
```

`configuration_reader.py` only has one function: parse the content we've specified in the configuration file. Since its is the only one who does any reading, in future iterations, it should also house any of the error checking for badly formatted config files. `get_configuration_settings()` does a simple reading of the `runtime_configurations.yaml` file and rips out the content.

I choose the `yaml` type as it offers benefits to both interacting as a user and for the program, as shown in the excerpt below:

```yaml
physical_constants: 
  speed_of_light: 1
  gravitational_constant: 1
spacetime_parameters:
  mass: 
    in_meters: 500
  charge: 0
  angular_momentum: 0
coordinate_domains:
  - dimension: "time"
    start: 0
    stop: 10
    step: 0.1
  - dimension: "reduced circumference" # as factors of M
    start: 2
    stop: 100
    step: 0.1
```

The indentation and dashes allow for logical distinction when the file is being read, similar to JSON files. Essentially, at the uppermost level, we have a dictionary with three keys: `physical_constants`, `spacetime_parameters`, and `coordinate_domains`. From there, its just another logical extension into further nested dictionaries. The power behind this implementation, is that not everything has to be specified.

By removing the `- dimension: "time"` entry, Cartographer will simply not create the time coordinate array. Also, by specifying the values for the physical constants here, it removes the possibility for incorrect plots when trying to use more accurate values for $c$ and $G$, and unintentionally forgetting to change one (or both) after running test data.

`schwarzschild.py` is where most of this data should live during runtime: as the arbiter of spacetime geometry, it should know the mass of the black hole and be responsible for answering questions asked about the geometry. I'm not sure exactly how to deal with different geometeries explicitly in the future, but for the moment, this seems to be the logical way forward.

`coordinate_array.py` is just a wrapper class for the `numpy` arrays.

```python
class Coordinate_Array:

  def __init__(self, start = int(), stop = int(), resolution = float()):
    dimensionless_start_value = remove_dimensions(start, resolution)
    dimensionless_stop_value = remove_dimensions(stop, resolution)
    self.step_resolution = resolution
    self.iteration_direction = (1 if (start < stop) else -1 )
    self.domain = np.arange( 
        dimensionless_start_value,
        dimensionless_stop_value,
        self.iteration_direction
      )

def remove_dimensions(value_to_remove_dimensions_from, dimensions_to_remove):
    return int(value_to_remove_dimensions_from / dimensions_to_remove)

def add_dimensions(value_to_add_dimensions_to, dimensionful_variable):
    return (value_to_add_dimensions_to * dimensionful_variable)
```

The only downside to splitting everything up into silos was that I still needed a way to ask about $dr_{bk}$ and $dt_{bk}$, but couldn't find out a way that using just the $initial$ and $final$ values with the $size$ of the array. 

\pagebreak

## Speed In Schwarzschild

### Limiting Cases and Optimization

The next logical step for plot functionality was implementing Equation 21 from *Exploring Black Holes*:

$$\frac{dr}{dt}=-\left(1-\frac{2M}{r}\right)\sqrt{\frac{2M}{r}}$$

```py
def get_bk_speed_at_geometric_position(r_coord):
  M = get_blackhole_mass_in_meters()
  speed = np.ones(np.shape(r_coord.domain))
  for r in r_coord.domain:
    speed[(r - r_coord.domain[0]) * r_coord.iteration_direction] = - (1 - (2*M)/(r*r_coord.step_resolution)) * np.sqrt((2*M)/(r*r_coord.step_resolution))
  return speed
```

Both the speed measure by the Bookkeeper and the speed recorded as the stone passes each shell were trivial to implement after having broken the monolith, however, runtimes have started to increase. In parallel, I had been consuming some content about `numpy` and `python` and was inspired to benchmark the results of this function call to see just how bad it was.

Fortunately, timing is very straightforward:

```py
import time
...
start = time.perf_counter()
speed = schwarzschild.get_bk_speed_at_geometric_position(r_coord)
stop = time.perf_counter()
print(f"Elapsed time: {stop-start}")
```

Where `time.perf_counter()` is described by the [docs](https://docs.python.org/3/library/time.html#functions) as:

> Return the value (in fractional seconds) of a performance counter, i.e. a clock with the highest available resolution to measure a short duration. It does include time elapsed during sleep and is system-wide. The reference point of the returned value is undefined, so that only the difference between the results of two calls is valid.



### Changing Perspective



