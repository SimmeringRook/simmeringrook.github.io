---
title: "Cartographer Progess Update"
subtitle: "10/29 - 11/5"
author: Thomas Knudson
papersize: a4
geometry: margin=2cm
output:
  pdf_document:
    toc: true
    toc_depth: 3
header-includes: |
    \usepackage{fancyhdr}
    \pagestyle{fancy}
    \fancyhead[RO,RE]{Knudson, For 11/5}
---

# Framework Scafolding

## Python

I learned a few interesting things about how Python deals with inheritance and classes.

- Class variables
    - 'Global' in scope, C# comparison is a 'static' class variable (shared across all instances)
- Polymorphism
    - either doesn't exist
    - or you just assume the thing you've been passed has the attributes you want to call
        - makes it harder to treat an abstract object
    - overriding methods is weird
        - sometimes still class the base class when executing
        - isn't horrible but requires a mental model reframing

## Latticework.py

Part of the focus here was to remove the dynamic initialization and population of the `nodes` array: E.g., this horrible abomination that was bound to break and cause issues in the future:

``` python
    def __populate_Lattice(self):
        # numpy.shape() returns a tuple describe the dimensions of the numpy array
        # We can asked for the
        numberOfDimensions = len(numpy.shape(self._nodes))
        print("Number of Dimensions:", numberOfDimensions)

        for dimension in range(numberOfDimensions):
            print("Length of Dimension:", numpy.shape(self._nodes)[dimension])

        for x in range(numpy.shape(self._nodes)[numberOfDimensions - numberOfDimensions]):
            for y in range(numpy.shape(self._nodes)[numberOfDimensions
                - numberOfDimensions + 1]):
                if (numberOfDimensions - numberOfDimensions + 2) < numberOfDimensions:
                    for z in range(numpy.shape(self._nodes)[numberOfDimensions -
                        numberOfDimensions + 2]):
                        if (numberOfDimensions - numberOfDimensions + 3) <
                            numberOfDimensions:
                            for t in range(numpy.shape(self._nodes)[numberOfDimensions
                                - numberOfDimensions + 3]):
                                self._nodes[x,y,z,t] = Node(tuple((x,y,z,t)))
                        else:
                            self._nodes[x,y,z] = Node(tuple((x,y,z)))
                else:
                    self._nodes[x,y] = Node(tuple((x,y)))
```

The concept was to implement some pre-optimization in which the N-dimensional `nodes` array only created the correct number of dimensions as required by the given `SpacetimeGeometry` being used as the basis. For example, if Cartographer was told to create a 1+1 representation of Schwarzschild spacetime, `nodes` only needs to be a 2-dimensional array: 1 spatial and 1 temporal. The above function could be cleaned up, to remove all the redundant `numberOfDimensions - numberOfDimensions` calculations [^1]:

[^1]: Ironically, the design decision behind this was to avoid hardcoding the indices for the different dimensions in each loop, but ultimately failed as the `Node` class wants to know its index position in the N-dimensional array. This design decision came about from previous hobby experience in game design where it becomes very useful for each tile in a board to be able to inform you of its coordinates: E.g., very helpful when needing to access neighbors.

``` python
    def __populate_Lattice(self):
        # ...
        for x in range(numpy.shape(self._nodes)[0]):
            for y in range(numpy.shape(self._nodes)[1]):
                if 2 < numberOfDimensions:
                    for z in range(numpy.shape(self._nodes)[2]):
                        if 3 < numberOfDimensions:
                            for t in range(numpy.shape(self._nodes)[3]):
                                self._nodes[x,y,z,t] = Node(tuple((x,y,z,t)))
                        else:
                            self._nodes[x,y,z] = Node(tuple((x,y,z)))
                else:
                    self._nodes[x,y] = Node(tuple((x,y)))
```

But that doesn't solve the underlying problem that this implementation:

- is hard to read and interpret
- makes assumptions about the geometry

While the loop variables have no 'direct' influence on what information is stored in `nodes`, they are revealing an implicit intended structure which is intentionally supposed to be absent. Ultimately, this was supposed to be resolved by having the onus be placed on Cartographer. If the user is asking for a specific latticework structure, they would be able to tell Cartographer how big each dimension needs to be and how many via the `gridShape` parameter in the class constructor:

```python
    def __init__(self, gridShape = tuple((4,4)), spacetime = EuclideanGeometry(2)):
        self._spacetime = spacetime
        self._nodes = numpy.empty(gridShape, dtype=object)
```
The details of initializing each `Node` in `nodes` was delayed until later, with a focus to getting a simple deliverable ready by Friday. Cartographer is supposed to generate plots of objects in spacetime and so figuring out how to generate those figures became more of a priority than the architecture of the framework.

## Cartographer.py

After resolving the weirdness of inheritance (and lack of polymorphism?) in Python, work focused on getting correct 'measurements' in Spacetime. Euclidean geometry uses the Pythagorean theorem to measure distances, so creating two points in separate orthogonal directions would be a simple test of the implementation. Similarly, the implementation of the metric for Minkowski spacetime should require only minor tweaking and both cases will serve as simple tests to verify the implementation works regardless of the geometry. In `Cartographer.py`, the following was added for this purpose:

```python
def main():
    gridsize = tuple((4,4,4,1))
    lattice = Latticework(gridsize)

    dx = tuple((2,0,0,0))
    dy = tuple((0,2,0,0))
    dt = tuple((0,0,0,4))

    euclideanPath = mark_out_path(dx,dy)
    minkowskiPath = mark_out_path(dx,dt)

    print("Euclidean:", euclideanPath, lattice._spacetime.Act_Metric_On(
        euclideanPath,euclideanPath))
    lattice._spacetime = SchwarzschildGeometry()
    print("Schwarzschild:", minkowskiPath, lattice._spacetime.Act_Metric_On(
        minkowskiPath,minkowskiPath))

def mark_out_path(start, stop):
    return tuple(map(lambda i, j: i - j, start, stop))
```

`mark_out_path` is just a minor helper function to create the (directed) line segment that connect the second point to the first. `lattice` was initialized with default parameters and so the type of `SpacetimeGeometry` assigned to `lattice._spacetime` was a 2-dimensional `EuclideanGeometry`. This child class really only serves to assign the correct metric signature to be used in calculations. The result given by `lattice._spacetime.Act_Metric_On` is then equivalent to asking for the squared magnitude of the vector. Taking the square root was omitted at this step as that's something to occur after the metric is used.

```
/GitHub/Cartographer/Cartographer.py
Creating Geometry with the metric: (1, 1)
Euclidean: (2, -2, 0, 0) 8
Creating Geometry with the metric: (1, 1, 1, -1)
Schwarzschild: (2, 0, 0, -4) -12
```

### EuclideanGeometry.py

```python
from SpacetimeGeometry import SpacetimeGeometry

class EuclideanGeometry(SpacetimeGeometry):

    __Metric = tuple(( tuple((1,)), tuple((1,1)), tuple((1,1,1)) ))

    def __init__(self, dimesionality=2):
        super().__init__(EuclideanGeometry.__Metric[
            len(EuclideanGeometry.__Metric) - dimesionality])
```

### SpacetimeGeometry.py

Since the default metric in `SpacetimeGeometry` (at this time) is 3+1 Minkowski, a `MinkowskiGeometry` has not been implemented yet.

```python
class SpacetimeGeometry:

    #__Metric = tuple((1,1,1,-1))

    def __init__(self, metric=tuple((1,1,1,-1))):
        print("Creating Geometry with the metric:", metric)
        self.__metric = metric

    def get_Dimensionality(self):
        return len(self.__metric)

    def Act_Metric_On(self, pForm1, pForm2):
        metricResult = 0
        for i in range(len(self.__metric)):
            metricResult += pForm1[i] * self.__metric[i] * pForm2[i]
        return metricResult
```

## Final Woes of Architecture

The natural next step was to move on to implementing `SchwarzschildGeometry` and that's where this approach came to a halt. Mathematically, it's a trivial matter to tell you how the metric acts on 1-forms for Schwarzschild:

$$\begin{aligned}
g(dr,dr) &= \frac{1}{1-\frac{2M}{r}} \\
g(r\sin{\theta}d\phi, r\sin{\theta}d\phi) &= 1 \\
g(rd\theta, rd\theta) &= 1 \\
g(dt,dt) &= -(1-\frac{2M}{r})
\end{aligned}$$

And in other Computer-Aided Algebra systems like Mathematica, the parameterization is equally as trivial: we just declare the dependence on the parameter called `r`. Python won't immediately freak out if we try to do this:

```python
#...
    self.__metric = tuple( (1/math.sqrt(1-2*M/r), 1, 1, math.sqrt(1-2*M/r)) )
```

We can always specify the mass of the black hole (in meters), `M`, globally or handle the scope differently. The problem is "what is `r`?" and "how do we tell the script later on that `r` now has a new value?". There are workarounds to avoid hardcoding the value, but this was just deeper and deeper into the weeds of architecture and no where closer to even getting a simple plot of Minkowski (or even Euclidean!) space.

\pagebreak

# Design Shift: Figures first, Grand Architecture later

With even more focused being place on the generation of figures, the question shifted to "how?". At this point, it is out of scope to build a plotting/graphic framework from scratch and I intended for Cartographer to be able to both export data (save on calculations in the future) and generate the figures, with the inkling of utilizing Matplotlib to format everything. So, keeping things as simple as possible and mentally reframing the project as a simple PH36X: Computational Lab assignment, the ingloriously named `plot.py` file was created. In defiance of experience, caution about future interoperability and extension was thrown to the wind to focus on direct implementation of equations of motion in Schwarzschild.

## Arrays

Matplotlib prefers to have an array for both the horizontal and vertical axes[^2] and so `tcoord` and `rcoord` are created with a size to represent the desired time and r-coordinate range.

[^2]: This makes a lot more sense in hindsight, considering how Microsoft Excel or Google Sheets require the columns for both as well.

``` python
tcoord = np.arange(0, int(tau_final/bookkeeper_timestep))
rcoord = np.arange( int(2*M), int( (r_max*M)/bookkeeper_rstep ) )
```

### Resolution Factor Explaination

This is done using the [Numpy `arange`](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) function which finds the integer distance between the given `start` and `stop` parameters such that the total length is the integer value of $$\frac{\text{stop} - \text{start}}{\text{step size}}$$ and initializes each element to the corresponding integer between `start` and `stop` (in increments of `step`). To avoid the singularity of $r=0$, `rcoord` is being initialized at $r=2M$. Both coordinate arrays also have their stop value scaled inversely by the `bookeeper_step` variables which represent the resolution of each calculation. For example, consider the implementation of finding the area under the curve of $x^2$:

``` python
dx = 1
xcoord = np.arange(0, a)

approximate_area = 0

for x in xcoord:
    approximate_area += np.power(x, 2) * dx
```

In this Riemann sum approximation of the integral, we can decrease the magnitude of `dx` to correspond to smaller width rectangles and increase our precision. However, `xcoord`'s size doesn't change dynamically to reflect this, and so we need to scale the length of this array proportionally. I've already revealed the method in which I intend to handle this dynamically and so I'll keep the derivation short: In the current form, if we want to reduce the width from $1$ unit to $0.1$, we then scale $a$ by $10$:

``` python
dx = 0.1
xcoord = np.arange(0, 10*a)
```

After playing around with different scale factors and inevitably forgetting to update all the values at the same time, the trick to notice is that inverse linear relationship. The only extra step involved is to ensure the result of dividing $a$ by $dx$ is an integer and so we arrive at the implementation for `rcoord` and `tcoord`:

``` python
bookkeeper_timestep = 0.1
bookkeeper_rstep = 1

tcoord = np.arange(0, int(tau_final/bookkeeper_timestep))
rcoord = np.arange( int(2*M), int( (r_max*M)/bookkeeper_rstep ) )
```

### Calculation Results

Since the plots I'm creating (at this stage) are scatter plots (with line segments connecting the points), I need a equivalently sized array to store the values for each calculation. Luckily, this is a very common use case for the developers/maintainers of Numpy, and their array constructing function calls accept a `np.shape()` call as a parameter to define the size. At the current moment, I could just ask the corresponding coordinate array for its `length` and construct it this way, but the power of using `np.shape()` is that this construction dynamically scales for whatever dimensionality of the given coordinate array. Since `np.shape()` returns a `tuple` (ordered and unchangeable collection) describing the dimensionality of the given array, this drastically simplifies the construction of a multidimensional array:

> Consider an example in which we need to store the results from $f(x,y,z)$ with $x\in[x_1, x_2]$, $y\in[y_1, y_2]$, and $z\in[z_1, z_2]$:

``` python
x_length = int(x2 - x1)
y_length = int(y2 - y1)
z_length = int(z2 - z1)

dimensionality_for_array = (x_length, y_length, z_length)

results = np.zeros( dimensionality_for_array )
```

This only leaves the function call of `np.zeros()`, which creates the array of specified dimensions and initializes each element to $0$. At this point, we're not iterating through the array's to check for specific values and this could foreseeably hide a bug in some calculation in which the results are returning $0$ incorrectly, but it does give us a starting point. If there is a significant math error it should manifest itself as a runtime error at this stage. It might be safer in the future to default to a `NaN` initialization, since the type returned from each math function call is a float and we can use `NaN` to spot bad behavior.

``` python
radial_position_at_time_t = np.zeros( np.shape(tcoord) )
v_effective = np.zeros( np.shape(rcoord) )
phi_position_at_rcoord = np.zeros( np.shape(rcoord) )
```

## Math Functions

With the basic groundwork for plotting laid out, it came time to encoding the mathematical functions into Python. For ease of immediate implementation, J. Hartle's *Gravity: An Introduction to Einstein's General Relativity* was consulted for the analytic solutions to simple motion in Schwarzschild spacetime. Radial (reduced-circumference) position as a function of proper time was implemented first, as it was the most straightforward and simple (and to verify that Python and it's libraries were playing nice).

``` python
def radial_position_at_propertime(tau):
    '''
    Using Equation 9.38 from Page 198 of Hartle:
        r(tau) = (3/2)^(2/3) * (2M)^(1/3) * (tau_final - tau)^(2/3)

    Since (3/2) and (2M) are constant values, we can save some efficency by calculating
    these at the start of the script and just reference the pre-calcualted value using
    `rad_const`
    '''
    return ( rad_const * np.power( (tau_final - tau), (2/3.0) ) )
```

$$r(\tau) = \left(\frac{3}{2}\right)^{2/3}\left(2M\right)^{1/3}\left(\tau_{final} - \tau \right)^{2/3}$$

The results were ... unenlightening: an almost perfect linear relationship. Having spent much time in the past plotting and changing the parameters of the effective potential function, that became the next focus of implementation as it would be easier to notice unexpected behaviour and determine the likely cause. Equation 9.30 from page 194 of Hartle defines the effective potential as:

$$V_{eff}(r) = \frac{1}{c^2}\left(-\frac{GM}{r} + \frac{\ell^2}{2r^2}-\frac{GM\ell^2}{c^2r^3}\right)$$

``` python
def effective_potential(rcoordinate, orbitalAngularMomentum):
    return (- (G*M)/rcoordinate + np.power( (orbitalAngularMomentum / rcoordinate), 2)
    * 0.5 - ( (G*M)/np.power(c, 2) ) * (np.power(orbitalAngularMomentum, 2)
        / np.power(rcoordinate, 3)) ) * (1/ np.power(c, 2))
```

For $\ell=5$, this creates the expected peak in the curve as $r\rightarrow 3M$ before decaying to $-\infty$ as $r\rightarrow 0$. Shortly before the scheduled meeting on 11/05, an attempt was made to implement a plot describing the scattering of a non-radial plunge trajectory. Equation 9.49 from page 201 of Hartle describes the change as:

$$\frac{d\phi}{dr} = \pm \frac{\ell^2}{r^2} \left[e^2 - \left(1-\frac{2M}{r}\right)\left(1+\frac{\ell^2}{r^2}\right)\right]^{-1/2}$$

And crudely implemented as:

``` python
def shape_of_bound_orbit(rcoordinate, orbitalAngularMomentum, totalenergy_per_unitrestmass):
    return (orbitalAngularMomentum / np.power(rcoordinate, 2))
     * 1 / np.power(( np.power(totalenergy_per_unitrestmass, 2) - (1 - (2*M)/rcoordinate)
     * (1 + np.power( (orbitalAngularMomentum / rcoordinate), 2) ) ), 0.5)
```

## plot.py

This is the full code file before the meeting began.

``` python
'''These are standard aliases for the packages; so I will opt to use standard notation for
 increased future readability'''
import numpy as np
import matplotlib.pyplot as plt

'''Physical constants'''
c = 1
M = 1
G = 1

'''Runtime constants'''
rad_const = np.power(1.5, (2/3.0)) * np.power(2*M, (1/3.0))
tau_final = 20.0
r_max = 40.0

'''Set Geometric scale factors'''
bookkeeper_timestep = 0.1
bookkeeper_rstep = 1

'''Arrays'''
tcoord = np.arange(0, int(tau_final/bookkeeper_timestep))
rcoord = np.arange( int(2*M), int( (r_max*M)/bookkeeper_rstep ) )

radial_position_at_time_t = np.zeros( np.shape(tcoord) )
v_effective = np.zeros( np.shape(rcoord) )
phi_position_at_rcoord = np.zeros( np.shape(rcoord) )

def shape_of_bound_orbit(rcoordinate, orbitalAngularMomentum, totalenergy_per_unitrestmass):
    return (orbitalAngularMomentum / np.power(rcoordinate, 2))
     * 1 / np.power(( np.power(totalenergy_per_unitrestmass, 2) - (1 - (2*M)/rcoordinate)
     * (1 + np.power( (orbitalAngularMomentum / rcoordinate), 2) ) ), 0.5)

def radial_position_at_propertime(tau):
    '''
    Using Equation 9.38 from Page 198 of Hartle:
        r(tau) = (3/2)^(2/3) * (2M)^(1/3) * (tau_final - tau)^(2/3)

    Since (3/2) and (2M) are constant values, we can save some efficency by calculating
    these at the start of the script and just reference the pre-calcualted value using
    `rad_const`
    '''
    return ( rad_const * np.power( (tau_final - tau), (2/3.0) ) )

def effective_potential(rcoordinate, orbitalAngularMomentum):
    return (- (G*M)/rcoordinate + np.power( (orbitalAngularMomentum / rcoordinate), 2)
    * 0.5 - ( (G*M)/np.power(c, 2) ) * (np.power(orbitalAngularMomentum, 2)
        / np.power(rcoordinate, 3)) ) * (1/ np.power(c, 2))

def make_plot(horizontalValues, verticalValues):
    fig, ax = plt.subplots()
    ax.plot(horizontalValues, verticalValues)
    plt.show()

def main():

    # for tau in tcoord:
    #     radial_position_at_time_t[tau - tcoord[0]] = radial_position_at_propertime(
        tau * bookkeeper_timestep)
    # make_plot(radial_position_at_time_t, tcoord)

    for r in rcoord:
        v_effective[r - rcoord[0]] = effective_potential(r, 5)
    #rescale the rcoordinates to be factors of M
    scaled_rcoord = np.multiply(rcoord, (bookkeeper_rstep/M) )
    make_plot(scaled_rcoord, v_effective)

if __name__ == '__main__':
    main()
```
